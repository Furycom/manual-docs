# VM 100 — Note VM — Vérité (facts-only) — 2026-02-02

## 0) Sources de preuve utilisées

* Proxmox: qm status/config/pendingconfig, qm listsnapshot, pvesm, lvs, lsblk.
* OS invité (si agent dispo): qm guest exec.

## 1) Identité VM (Proxmox)

### 1.1 Status
status: running

### 1.2 Config (qm config)
```
agent: enabled=1
balloon: 5120
bios: ovmf
boot: order=scsi0
cores: 2
cpu: host
description: SUPABASE %E2%80%94 VM 100 (projet local)%0A%0ABut %3A Plateforme Supabase auto-h%C3%A9berg%C3%A9e (Postgres + API + Auth + Studio).%0ASSH %3A ssh furycom@192.168.2.206 (port 22)%0AStudio / Gateway (LAN) %3A http%3A//192.168.2.206%3A8000%0APostgres via pooler (LAN) %3A 192.168.2.206%3A5432 (transactionnel) et %3A6543%0AAdmin Studio %3A identifiants dans SECRETS.txt (voir plus bas)%0A%0AUsername %3A supabase_admin%0A%0APassword %3A epoxZM8ibhL53Q8MzOr4Vg%0A%0A1) Inventaire rapide%0A%0AOS %3A Ubuntu 24.04 LTS, kernel 6.8%0A%0ARessources %3A 2 vCPU, 8 GiB RAM (balloon OFF)%0A%0AR%C3%A9seau %3A enp6s18 %E2%80%94 IP DHCP r%C3%A9serv%C3%A9e 192.168.2.206%0A%0APare-feu (UFW) %3A%0A%0AALLOW LAN 8000/tcp, 5432/tcp, 6543/tcp depuis 192.168.2.0/24%0A%0AALLOW OpenSSH, deny incoming par d%C3%A9faut%0A%0AAgent invit%C3%A9 %3A QEMU Guest Agent install%C3%A9/actif%0A%0ADocker %3A data-root = /srv/docker ; Compose plugin install%C3%A9%0A%0AAuto-start Supabase %3A service systemd supabase.service%0A%0A%0A%0A2) Arborescence & chemins utiles%0A%0AProjet Supabase (compose) %3A%0A%0ADossier %3A /srv/supabase/supabase-project%0A%0AFichiers %3A docker-compose.yml, .env%0A%0ASecrets sauvegard%C3%A9s (root-only) %3A /srv/supabase/supabase-project/SECRETS.txt (chmod 600)%0A%0AVolumes / donn%C3%A9es %3A%0A%0ADisque OS %3A scsi0 60 G (LVM) %E2%86%92 /%0A%0ADisque donn%C3%A9es %3A scsi1 600 G (ext4) %E2%86%92 mont%C3%A9 sur /srv/supabase%0A%0APorts locaux expos%C3%A9s %3A%0A%0A8000 (Kong/Studio), 5432 & 6543 (Supavisor pooler), 4000 (logflare, debug), 3000/5000 internes%0A%0A3) Acc%C3%A8s & identifiants%0A%0ASSH %3A utilisateur furycom (sudo)%0A%0AStudio (GUI) %3A DASHBOARD_USERNAME / DASHBOARD_PASSWORD%0A%0ANe pas %C3%A9crire les mots de passe ici. Source de v%C3%A9rit%C3%A9 %3A%0A%0A.env (cl%C3%A9%3A DASHBOARD_USERNAME, DASHBOARD_PASSWORD)%0A%0ASECRETS.txt (r%C3%A9capitulatif root-only)%0A%0A%0A%0A4) Exploitation quotidienne (cheat-sheet)%0A%C3%89tat & logs%0Acd /srv/supabase/supabase-project%0Adocker compose ps%0Adocker compose logs --tail=100 -f%0Adocker stats --no-stream%0Asystemctl status supabase%0Ajournalctl -u supabase -e%0A%0A%0A(Re)lancer / arr%C3%AAter Supabase%0Asystemctl start supabase%0Asystemctl stop supabase%0A# Ou directement %3A%0Adocker compose up -d%0Adocker compose down%0A%0A%0AMise %C3%A0 jour des images Supabase%0Acd /srv/supabase/supabase-project%0Adocker compose pull%0Adocker compose up -d%0A%0A%0AModifier des secrets / l%E2%80%99URL du site%0A%0A%C3%89diter .env, puis %3A%0Adocker compose up -d%0A%0A%0A%0A5) Sauvegardes (minimum vital)%0A%0AConfig & secrets %3A%0A%0ASauvegarder /srv/supabase/supabase-project/.env%0A%0ASauvegarder /srv/supabase/supabase-project/SECRETS.txt (root-only)%0A%0ADonn%C3%A9es Postgres/Storage %3A snapshot VM Proxmox ou sauvegarde des volumes Docker (%C3%A0 d%C3%A9finir en 1D).%0A%0A6) Sant%C3%A9 & particularit%C3%A9s%0A%0ATous les services sont healthy sauf realtime qui peut appara%C3%AEtre unhealthy (check HTTP renvoie 403) %E2%80%94 sans impact si Realtime n%E2%80%99est pas utilis%C3%A9.%0A%0Ahttp%3A//IP%3A8000 renvoie 401 sans authent %E2%80%94 normal (Kong prot%C3%A8ge l%E2%80%99acc%C3%A8s, se connecter via Studio avec user/pass).%0A%0A7) Proxmox / stockage%0A%0AStorage VM %3A pool LVM-thin vmstore/vmdata (auto-extend activ%C3%A9)%0A%0ASnapshots rep%C3%A8res %3A fin-1B-final (%C3%A9tat stable post-d%C3%A9ploiement)%0A%0AConseill%C3%A9 %3A conserver uniquement le dernier snapshot utile.%0A%0A8) S%C3%A9curit%C3%A9 / r%C3%A9seau%0A%0AServices ouverts au LAN uniquement (UFW).%0A%0AAucune exposition publique configur%C3%A9e. Si exposition Internet %3A pr%C3%A9voir reverse-proxy + TLS et durcir les ACL.%0A%0A9) Prochaine %C3%A9tape sugg%C3%A9r%C3%A9e%0A%0A1D %E2%80%94 Sauvegardes & monitoring %3A script de backup Postgres + sauvegarde des fichiers .env/SECRETS, rotation/prune Docker, alertes simples.%0A%0A1C %E2%80%94 VM LLM (GPU) %3A %C3%A0 cr%C3%A9er s%C3%A9par%C3%A9ment quand la GTX 1060 sera en passthrough.%0A%0A%0A(Ces notes d%C3%A9crivent l%E2%80%99%C3%A9tat apr%C3%A8s 1B %3A Supabase op%C3%A9rationnel, autostart, UFW, disques configur%C3%A9s, secrets centralis%C3%A9s.)
efidisk0: vmhdd:vm-100-disk-1,size=4M
machine: q35
memory: 8192
meta: creation-qemu=10.0.2,ctime=1756432975
name: supabase-vm
net0: virtio=BC:24:11:1D:F0:6E,bridge=vmbr0
onboot: 1
ostype: l26
parent: beforehttpapi
scsi0: vmhdd:vm-100-disk-0,discard=on,iothread=1,size=60G,ssd=1
scsi1: vmhdd:vm-100-disk-2,discard=on,iothread=1,size=600G
scsihw: virtio-scsi-single
serial0: socket
smbios1: uuid=5cd10d8d-e55f-418b-938a-ce47048bff13
vga: serial0
vmgenid: 0a56cf2e-3912-448f-becc-19fbbefdff1d
```

### 1.3 Pending config (si présent)
```
cur agent: enabled=1
cur balloon: 5120
cur bios: ovmf
cur boot: order=scsi0
cur cores: 2
cur cpu: host
cur description: SUPABASE %E2%80%94 VM 100 (projet local)%0A%0ABut %3A Plateforme Supabase auto-h%C3%A9berg%C3%A9e (Postgres + API + Auth + Studio).%0ASSH %3A ssh furycom@192.168.2.206 (port 22)%0AStudio / Gateway (LAN) %3A http%3A//192.168.2.206%3A8000%0APostgres via pooler (LAN) %3A 192.168.2.206%3A5432 (transactionnel) et %3A6543%0AAdmin Studio %3A identifiants dans SECRETS.txt (voir plus bas)%0A%0AUsername %3A supabase_admin%0A%0APassword %3A epoxZM8ibhL53Q8MzOr4Vg%0A%0A1) Inventaire rapide%0A%0AOS %3A Ubuntu 24.04 LTS, kernel 6.8%0A%0ARessources %3A 2 vCPU, 8 GiB RAM (balloon OFF)%0A%0AR%C3%A9seau %3A enp6s18 %E2%80%94 IP DHCP r%C3%A9serv%C3%A9e 192.168.2.206%0A%0APare-feu (UFW) %3A%0A%0AALLOW LAN 8000/tcp, 5432/tcp, 6543/tcp depuis 192.168.2.0/24%0A%0AALLOW OpenSSH, deny incoming par d%C3%A9faut%0A%0AAgent invit%C3%A9 %3A QEMU Guest Agent install%C3%A9/actif%0A%0ADocker %3A data-root = /srv/docker ; Compose plugin install%C3%A9%0A%0AAuto-start Supabase %3A service systemd supabase.service%0A%0A%0A%0A2) Arborescence & chemins utiles%0A%0AProjet Supabase (compose) %3A%0A%0ADossier %3A /srv/supabase/supabase-project%0A%0AFichiers %3A docker-compose.yml, .env%0A%0ASecrets sauvegard%C3%A9s (root-only) %3A /srv/supabase/supabase-project/SECRETS.txt (chmod 600)%0A%0AVolumes / donn%C3%A9es %3A%0A%0ADisque OS %3A scsi0 60 G (LVM) %E2%86%92 /%0A%0ADisque donn%C3%A9es %3A scsi1 600 G (ext4) %E2%86%92 mont%C3%A9 sur /srv/supabase%0A%0APorts locaux expos%C3%A9s %3A%0A%0A8000 (Kong/Studio), 5432 & 6543 (Supavisor pooler), 4000 (logflare, debug), 3000/5000 internes%0A%0A3) Acc%C3%A8s & identifiants%0A%0ASSH %3A utilisateur furycom (sudo)%0A%0AStudio (GUI) %3A DASHBOARD_USERNAME / DASHBOARD_PASSWORD%0A%0ANe pas %C3%A9crire les mots de passe ici. Source de v%C3%A9rit%C3%A9 %3A%0A%0A.env (cl%C3%A9%3A DASHBOARD_USERNAME, DASHBOARD_PASSWORD)%0A%0ASECRETS.txt (r%C3%A9capitulatif root-only)%0A%0A%0A%0A4) Exploitation quotidienne (cheat-sheet)%0A%C3%89tat & logs%0Acd /srv/supabase/supabase-project%0Adocker compose ps%0Adocker compose logs --tail=100 -f%0Adocker stats --no-stream%0Asystemctl status supabase%0Ajournalctl -u supabase -e%0A%0A%0A(Re)lancer / arr%C3%AAter Supabase%0Asystemctl start supabase%0Asystemctl stop supabase%0A# Ou directement %3A%0Adocker compose up -d%0Adocker compose down%0A%0A%0AMise %C3%A0 jour des images Supabase%0Acd /srv/supabase/supabase-project%0Adocker compose pull%0Adocker compose up -d%0A%0A%0AModifier des secrets / l%E2%80%99URL du site%0A%0A%C3%89diter .env, puis %3A%0Adocker compose up -d%0A%0A%0A%0A5) Sauvegardes (minimum vital)%0A%0AConfig & secrets %3A%0A%0ASauvegarder /srv/supabase/supabase-project/.env%0A%0ASauvegarder /srv/supabase/supabase-project/SECRETS.txt (root-only)%0A%0ADonn%C3%A9es Postgres/Storage %3A snapshot VM Proxmox ou sauvegarde des volumes Docker (%C3%A0 d%C3%A9finir en 1D).%0A%0A6) Sant%C3%A9 & particularit%C3%A9s%0A%0ATous les services sont healthy sauf realtime qui peut appara%C3%AEtre unhealthy (check HTTP renvoie 403) %E2%80%94 sans impact si Realtime n%E2%80%99est pas utilis%C3%A9.%0A%0Ahttp%3A//IP%3A8000 renvoie 401 sans authent %E2%80%94 normal (Kong prot%C3%A8ge l%E2%80%99acc%C3%A8s, se connecter via Studio avec user/pass).%0A%0A7) Proxmox / stockage%0A%0AStorage VM %3A pool LVM-thin vmstore/vmdata (auto-extend activ%C3%A9)%0A%0ASnapshots rep%C3%A8res %3A fin-1B-final (%C3%A9tat stable post-d%C3%A9ploiement)%0A%0AConseill%C3%A9 %3A conserver uniquement le dernier snapshot utile.%0A%0A8) S%C3%A9curit%C3%A9 / r%C3%A9seau%0A%0AServices ouverts au LAN uniquement (UFW).%0A%0AAucune exposition publique configur%C3%A9e. Si exposition Internet %3A pr%C3%A9voir reverse-proxy + TLS et durcir les ACL.%0A%0A9) Prochaine %C3%A9tape sugg%C3%A9r%C3%A9e%0A%0A1D %E2%80%94 Sauvegardes & monitoring %3A script de backup Postgres + sauvegarde des fichiers .env/SECRETS, rotation/prune Docker, alertes simples.%0A%0A1C %E2%80%94 VM LLM (GPU) %3A %C3%A0 cr%C3%A9er s%C3%A9par%C3%A9ment quand la GTX 1060 sera en passthrough.%0A%0A%0A(Ces notes d%C3%A9crivent l%E2%80%99%C3%A9tat apr%C3%A8s 1B %3A Supabase op%C3%A9rationnel, autostart, UFW, disques configur%C3%A9s, secrets centralis%C3%A9s.)
cur efidisk0: vmhdd:vm-100-disk-1,size=4M
cur machine: q35
cur memory: 8192
cur meta: creation-qemu=10.0.2,ctime=1756432975
cur name: supabase-vm
cur net0: virtio=BC:24:11:1D:F0:6E,bridge=vmbr0
cur onboot: 1
cur ostype: l26
cur parent: beforehttpapi
cur scsi0: vmhdd:vm-100-disk-0,discard=on,iothread=1,size=60G,ssd=1
cur scsi1: vmhdd:vm-100-disk-2,discard=on,iothread=1,size=600G
cur scsihw: virtio-scsi-single
cur serial0: socket
cur smbios1: uuid=5cd10d8d-e55f-418b-938a-ce47048bff13
cur vga: serial0
cur vmgenid: 0a56cf2e-3912-448f-becc-19fbbefdff1d
```

### 1.4 Snapshots (qm listsnapshot)
```
`-> beforehttpapi               2025-12-03 08:49:26     juste avant modif
 `-> current                                            You are here!
```

## 2) Disques et stockage (Proxmox)

### 2.1 Disques VM (extraits qm config)
```
4:boot: order=scsi0
5:cores: 2
6:cpu: host
10:memory: 8192
17:scsi0: vmhdd:vm-100-disk-0,discard=on,iothread=1,size=60G,ssd=1
18:scsi1: vmhdd:vm-100-disk-2,discard=on,iothread=1,size=600G
19:scsihw: virtio-scsi-single
```

### 2.2 Stockages (pvesm status)
```
Name             Type     Status     Total (KiB)      Used (KiB) Available (KiB)        %
local             dir     active        38727016        11398804        25328752   29.43%
local-lvm     lvmthin     active        66560000        41546752        25013248   62.42%
vmhdd         lvmthin     active       927920128       212215333       715704794   22.87%
```

### 2.3 Disques physiques (lsblk)
```
NAME                                  SIZE TYPE FSTYPE      MOUNTPOINT MODEL
sda                                 931.5G disk LVM2_member            APPLE HDD ST1000DM003
├─vmstore-vmdata_tmeta                  1G lvm                         
│ └─vmstore-vmdata-tpool            884.9G lvm                         
│   ├─vmstore-vmdata                884.9G lvm                         
│   ├─vmstore-vm--100--disk--0         60G lvm                         
│   ├─vmstore-vm--100--disk--2        600G lvm                         
│   ├─vmstore-vm--100--disk--1          4M lvm                         
│   ├─vmstore-vm--102--disk--0         32G lvm                         
│   ├─vmstore-vm--102--disk--1          4M lvm                         
│   ├─vmstore-vm--111--disk--1        100G lvm                         
│   ├─vmstore-vm--111--disk--0          4M lvm                         
│   ├─vmstore-vm--103--disk--1         60G lvm                         
│   ├─vmstore-vm--103--disk--0          4M lvm                         
│   ├─vmstore-vm--102--state--renow  10.5G lvm                         
│   ├─vmstore-vm--101--disk--0          4M lvm                         
│   └─vmstore-vm--101--disk--1         32G lvm                         
└─vmstore-vmdata_tdata              884.9G lvm                         
  └─vmstore-vmdata-tpool            884.9G lvm                         
    ├─vmstore-vmdata                884.9G lvm                         
    ├─vmstore-vm--100--disk--0         60G lvm                         
    ├─vmstore-vm--100--disk--2        600G lvm                         
    ├─vmstore-vm--100--disk--1          4M lvm                         
    ├─vmstore-vm--102--disk--0         32G lvm                         
    ├─vmstore-vm--102--disk--1          4M lvm                         
    ├─vmstore-vm--111--disk--1        100G lvm                         
    ├─vmstore-vm--111--disk--0          4M lvm                         
    ├─vmstore-vm--103--disk--1         60G lvm                         
    ├─vmstore-vm--103--disk--0          4M lvm                         
    ├─vmstore-vm--102--state--renow  10.5G lvm                         
    ├─vmstore-vm--101--disk--0          4M lvm                         
    └─vmstore-vm--101--disk--1         32G lvm                         
sdb                                 111.8G disk                        ST120FP0021
├─sdb1                               1007K part                        
├─sdb2                                  1G part vfat        /boot/efi  
└─sdb3                                110G part LVM2_member            
  ├─pve-swap                          6.7G lvm  swap        [SWAP]     
  ├─pve-root                         37.8G lvm  ext4        /          
  ├─pve-data_tmeta                      1G lvm                         
  │ └─pve-data-tpool                 63.5G lvm                         
  │   ├─pve-data                     63.5G lvm                         
  │   ├─pve-vm--103--disk--0           20G lvm                         
  │   └─pve-vm--103--state--sureter   8.5G lvm                         
  └─pve-data_tdata                   63.5G lvm                         
    └─pve-data-tpool                 63.5G lvm                         
      ├─pve-data                     63.5G lvm                         
      ├─pve-vm--103--disk--0           20G lvm                         
      └─pve-vm--103--state--sureter   8.5G lvm                         
```

## 3) OS invité via QEMU Guest Agent (si disponible)

* Agent: OK

### 3.1 Hostname / kernel / uptime
```
{
   "exitcode" : 0,
   "exited" : 1,
   "out-data" : "supabase\nLinux supabase 6.8.0-90-generic #91-Ubuntu SMP PREEMPT_DYNAMIC Tue Nov 18 14:14:30 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux\n 19:46:37 up 22:19,  1 user,  load average: 0,32, 0,36, 0,39\n"
}
```

### 3.2 Réseau (ip -br a)
```
{
   "exitcode" : 0,
   "exited" : 1,
   "out-data" : "lo               UNKNOWN        127.0.0.1/8 ::1/128 \nenp6s18          UP             192.168.2.206/24 fe80::be24:11ff:fe1d:f06e/64 \nbr-5b8d17163577  UP             172.18.0.1/16 fe80::1c70:b2ff:fe0d:b128/64 \ndocker0          UP             172.17.0.1/16 fe80::848c:efff:feea:9072/64 \nveth55e3a59@if2  UP             fe80::606b:51ff:fe58:4029/64 \nveth6402211@if2  UP             fe80::d449:d2ff:fe74:9422/64 \nveth9d1f21c@if2  UP             fe80::3807:4cff:fef9:48c3/64 \nvethf2720ed@if2  UP             fe80::7c89:29ff:feb2:e379/64 \nveth6a10d42@if2  UP             fe80::1c53:13ff:fe56:8cd0/64 \nvethacc61e0@if2  UP             fe80::2cfd:74ff:feb7:d059/64 \nveth4384d6a@if2  UP             fe80::8cb1:1bff:fe0b:528f/64 \nvethaa4511b@if2  UP             fe80::f064:65ff:feb5:7e2b/64 \nvethf7f23e8@if2  UP             fe80::fcde:3eff:fe9f:9066/64 \nveth16362f6@if2  UP             fe80::6ca8:a3ff:fe97:f553/64 \nveth048be60@if2  UP             fe80::b0a9:cfff:fe4c:2786/64 \nveth021e817@if2  UP             fe80::ccdd:7eff:fe4c:2e65/64 \nveth39085df@if2  UP             fe80::f85d:82ff:feda:2e7a/64 \nvethddf90d8@if2  UP             fe80::302a:8dff:fecc:1f37/64 \nveth9999329@if2  UP             fe80::2027:c0ff:fea0:9b90/64 \n"
}
```

### 3.3 Disques (lsblk) + FS (df -hT)
```
{
   "exitcode" : 0,
   "exited" : 1,
   "out-data" : "NAME                        SIZE TYPE FSTYPE      MOUNTPOINT\nloop0                     104,2M loop             /snap/core/17247\nloop1                       105M loop             /snap/core/17272\nloop2                      38,7M loop             /snap/postgresql10/47\nloop3                      50,9M loop             /snap/snapd/25577\nloop4                      48,1M loop             /snap/snapd/25935\nsda                          60G disk             \nââsda1                        1G part vfat        /boot/efi\nââsda2                        2G part ext4        /boot\nââsda3                     56,9G part LVM2_member \n  ââubuntu--vg-ubuntu--lv  56,9G lvm  ext4        /\nsdb                         600G disk             \nââsdb1                      600G part ext4        /srv/supabase\n"
}
```

```
{
   "exitcode" : 0,
   "exited" : 1,
   "out-data" : "Filesystem                        Type      Size  Used Avail Use% Mounted on\ntmpfs                             tmpfs     767M  2,5M  765M   1% /run\nefivarfs                          efivarfs   56K   24K   28K  46% /sys/firmware/efi/efivars\n/dev/mapper/ubuntu--vg-ubuntu--lv ext4       56G   24G   30G  45% /\ntmpfs                             tmpfs     2,5G     0  2,5G   0% /dev/shm\ntmpfs                             tmpfs     5,0M     0  5,0M   0% /run/lock\n/dev/sda2                         ext4      2,0G  193M  1,6G  11% /boot\n/dev/sdb1                         ext4      590G  1,9G  558G   1% /srv/supabase\n/dev/sda1                         vfat      1,1G  6,2M  1,1G   1% /boot/efi\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/20732597bb41fa219e2a1922da6859a13ff6425da04de0b52640be9965e9700a/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/458dbabb73060fce32a8e5d341a3b3526868b33b05a8a82040c4bd5c0961ab4f/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/422766ee928f10c4054d60c37bf50d1202b98cf28db2791788a48af2302db39d/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/ae6f20b68a82d2fa9c95d66a618090ee816e9b041cebb601f92c60b01b6ac6d3/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/b48e055d044d953add5823e82720478443583839e1512d6784fcc464747b0e83/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/41cacd0ecab25955bf1c3320d136efbbfa275cf76274543fa3c2d43a8265d878/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/af18241c940c1e5a6c53803a9c9be4f231efaacc202251272e35a4d2b938997d/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/72a699faaa911409f65e4da73b944145d8a1241d71a56492e64a31eaee4cfcbd/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/3edd1c908e58255dfa81e87b9cf9c58169c27dd1ddbc7963ae0a7651cb406046/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/d2fe9e6ad96b2ea568d2efdc85480b251d848637acd71a64e808b8fde020c627/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/1c0bdca7f1d04ce6f7fc0e098189b2028059f4ed78ddfb345e457139feed86ac/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/d5f3d52e28ec9deda6774d28b04466b9c5a1718a5260a0138ada9aeda58ce93a/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/2c18a388f943b6353e838d5a373b2f4debcf0cb82c72217e2b03dd128e093089/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/0c9419190cfac6cb9f64a1a4878c0a6f4c5de55c1026d5744dbab4415e3117c2/merged\noverlay                           overlay    56G   24G   30G  45% /var/lib/docker/overlay2/e6b117eb49de29db95c1940390eea908e4f266ee67c12418635985cc302dde1b/merged\ntmpfs                             tmpfs     507M   12K  507M   1% /run/user/1000\n"
}
```

### 3.4 Ports en écoute (ss -lnt)
```
{
   "exitcode" : 0,
   "exited" : 1,
   "out-data" : "State  Recv-Q Send-Q Local Address:Port  Peer Address:PortProcess\nLISTEN 0      4096         0.0.0.0:6543       0.0.0.0:*          \nLISTEN 0      4096         0.0.0.0:3000       0.0.0.0:*          \nLISTEN 0      4096         0.0.0.0:7007       0.0.0.0:*          \nLISTEN 0      4096         0.0.0.0:4000       0.0.0.0:*          \nLISTEN 0      4096         0.0.0.0:8000       0.0.0.0:*          \nLISTEN 0      4096         0.0.0.0:8443       0.0.0.0:*          \nLISTEN 0      4096         0.0.0.0:22         0.0.0.0:*          \nLISTEN 0      4096         0.0.0.0:5432       0.0.0.0:*          \nLISTEN 0      4096      127.0.0.54:53         0.0.0.0:*          \nLISTEN 0      4096   127.0.0.53%lo:53         0.0.0.0:*          \nLISTEN 0      4096         0.0.0.0:54322      0.0.0.0:*          \nLISTEN 0      4096            [::]:6543          [::]:*          \nLISTEN 0      4096            [::]:3000          [::]:*          \nLISTEN 0      4096            [::]:7007          [::]:*          \nLISTEN 0      4096            [::]:4000          [::]:*          \nLISTEN 0      4096            [::]:8000          [::]:*          \nLISTEN 0      4096            [::]:8443          [::]:*          \nLISTEN 0      4096            [::]:22            [::]:*          \nLISTEN 0      4096            [::]:5432          [::]:*          \nLISTEN 0      4096            [::]:54322         [::]:*          \n"
}
```

### 3.5 Docker (si présent)
```
{
   "exitcode" : 0,
   "exited" : 1,
   "out-data" : "NAMES                            IMAGE                                    STATUS                  PORTS\nsupabase-pooler                  supabase/supavisor:2.5.7                 Up 22 hours (healthy)   0.0.0.0:5432->5432/tcp, [::]:5432->5432/tcp, 0.0.0.0:6543->6543/tcp, [::]:6543->6543/tcp\nsupabase-analytics               supabase/logflare:1.14.2                 Up 22 hours (healthy)   0.0.0.0:4000->4000/tcp, [::]:4000->4000/tcp\nrealtime-dev.supabase-realtime   supabase/realtime:v2.34.47               Up 22 hours (healthy)   \nsupabase-db-forward              alpine/socat                             Up 22 hours             0.0.0.0:54322->5432/tcp, [::]:54322->5432/tcp\ndozzle-agent                     amir20/dozzle:latest                     Up 22 hours             0.0.0.0:7007->7007/tcp, [::]:7007->7007/tcp, 8080/tcp\nsupabase-storage                 supabase/storage-api:v1.25.7             Up 22 hours (healthy)   5000/tcp\nsupabase-meta                    supabase/postgres-meta:v0.91.0           Up 22 hours (healthy)   8080/tcp\nsupabase-kong                    kong:2.8.1                               Up 22 hours (healthy)   0.0.0.0:8000->8000/tcp, [::]:8000->8000/tcp, 8001/tcp, 0.0.0.0:8443->8443/tcp, [::]:8443->8443/tcp, 8444/tcp\nsupabase-studio                  supabase/studio:2025.06.30-sha-6f5982d   Up 22 hours (healthy)   3000/tcp\nsupabase-edge-functions          supabase/edge-runtime:v1.67.4            Up 22 hours             \nsupabase-auth                    supabase/gotrue:v2.177.0                 Up 22 hours (healthy)   \nsupabase-rest                    postgrest/postgrest:v12.2.12             Up 22 hours             0.0.0.0:3000->3000/tcp, [::]:3000->3000/tcp\nsupabase-db                      supabase/postgres:15.8.1.060             Up 22 hours (healthy)   5432/tcp\nsupabase-vector                  timberio/vector:0.28.1-alpine            Up 22 hours (healthy)   \nsupabase-imgproxy                darthsim/imgproxy:v3.8.0                 Up 22 hours (healthy)   8080/tcp\n"
}
```

## 4) Notes Proxmox (description)

```
SUPABASE %E2%80%94 VM 100 (projet local)%0A%0ABut %3A Plateforme Supabase auto-h%C3%A9berg%C3%A9e (Postgres + API + Auth + Studio).%0ASSH %3A ssh furycom@192.168.2.206 (port 22)%0AStudio / Gateway (LAN) %3A http%3A//192.168.2.206%3A8000%0APostgres via pooler (LAN) %3A 192.168.2.206%3A5432 (transactionnel) et %3A6543%0AAdmin Studio %3A identifiants dans SECRETS.txt (voir plus bas)%0A%0AUsername %3A supabase_admin%0A%0APassword %3A epoxZM8ibhL53Q8MzOr4Vg%0A%0A1) Inventaire rapide%0A%0AOS %3A Ubuntu 24.04 LTS, kernel 6.8%0A%0ARessources %3A 2 vCPU, 8 GiB RAM (balloon OFF)%0A%0AR%C3%A9seau %3A enp6s18 %E2%80%94 IP DHCP r%C3%A9serv%C3%A9e 192.168.2.206%0A%0APare-feu (UFW) %3A%0A%0AALLOW LAN 8000/tcp, 5432/tcp, 6543/tcp depuis 192.168.2.0/24%0A%0AALLOW OpenSSH, deny incoming par d%C3%A9faut%0A%0AAgent invit%C3%A9 %3A QEMU Guest Agent install%C3%A9/actif%0A%0ADocker %3A data-root = /srv/docker ; Compose plugin install%C3%A9%0A%0AAuto-start Supabase %3A service systemd supabase.service%0A%0A%0A%0A2) Arborescence & chemins utiles%0A%0AProjet Supabase (compose) %3A%0A%0ADossier %3A /srv/supabase/supabase-project%0A%0AFichiers %3A docker-compose.yml, .env%0A%0ASecrets sauvegard%C3%A9s (root-only) %3A /srv/supabase/supabase-project/SECRETS.txt (chmod 600)%0A%0AVolumes / donn%C3%A9es %3A%0A%0ADisque OS %3A scsi0 60 G (LVM) %E2%86%92 /%0A%0ADisque donn%C3%A9es %3A scsi1 600 G (ext4) %E2%86%92 mont%C3%A9 sur /srv/supabase%0A%0APorts locaux expos%C3%A9s %3A%0A%0A8000 (Kong/Studio), 5432 & 6543 (Supavisor pooler), 4000 (logflare, debug), 3000/5000 internes%0A%0A3) Acc%C3%A8s & identifiants%0A%0ASSH %3A utilisateur furycom (sudo)%0A%0AStudio (GUI) %3A DASHBOARD_USERNAME / DASHBOARD_PASSWORD%0A%0ANe pas %C3%A9crire les mots de passe ici. Source de v%C3%A9rit%C3%A9 %3A%0A%0A.env (cl%C3%A9%3A DASHBOARD_USERNAME, DASHBOARD_PASSWORD)%0A%0ASECRETS.txt (r%C3%A9capitulatif root-only)%0A%0A%0A%0A4) Exploitation quotidienne (cheat-sheet)%0A%C3%89tat & logs%0Acd /srv/supabase/supabase-project%0Adocker compose ps%0Adocker compose logs --tail=100 -f%0Adocker stats --no-stream%0Asystemctl status supabase%0Ajournalctl -u supabase -e%0A%0A%0A(Re)lancer / arr%C3%AAter Supabase%0Asystemctl start supabase%0Asystemctl stop supabase%0A# Ou directement %3A%0Adocker compose up -d%0Adocker compose down%0A%0A%0AMise %C3%A0 jour des images Supabase%0Acd /srv/supabase/supabase-project%0Adocker compose pull%0Adocker compose up -d%0A%0A%0AModifier des secrets / l%E2%80%99URL du site%0A%0A%C3%89diter .env, puis %3A%0Adocker compose up -d%0A%0A%0A%0A5) Sauvegardes (minimum vital)%0A%0AConfig & secrets %3A%0A%0ASauvegarder /srv/supabase/supabase-project/.env%0A%0ASauvegarder /srv/supabase/supabase-project/SECRETS.txt (root-only)%0A%0ADonn%C3%A9es Postgres/Storage %3A snapshot VM Proxmox ou sauvegarde des volumes Docker (%C3%A0 d%C3%A9finir en 1D).%0A%0A6) Sant%C3%A9 & particularit%C3%A9s%0A%0ATous les services sont healthy sauf realtime qui peut appara%C3%AEtre unhealthy (check HTTP renvoie 403) %E2%80%94 sans impact si Realtime n%E2%80%99est pas utilis%C3%A9.%0A%0Ahttp%3A//IP%3A8000 renvoie 401 sans authent %E2%80%94 normal (Kong prot%C3%A8ge l%E2%80%99acc%C3%A8s, se connecter via Studio avec user/pass).%0A%0A7) Proxmox / stockage%0A%0AStorage VM %3A pool LVM-thin vmstore/vmdata (auto-extend activ%C3%A9)%0A%0ASnapshots rep%C3%A8res %3A fin-1B-final (%C3%A9tat stable post-d%C3%A9ploiement)%0A%0AConseill%C3%A9 %3A conserver uniquement le dernier snapshot utile.%0A%0A8) S%C3%A9curit%C3%A9 / r%C3%A9seau%0A%0AServices ouverts au LAN uniquement (UFW).%0A%0AAucune exposition publique configur%C3%A9e. Si exposition Internet %3A pr%C3%A9voir reverse-proxy + TLS et durcir les ACL.%0A%0A9) Prochaine %C3%A9tape sugg%C3%A9r%C3%A9e%0A%0A1D %E2%80%94 Sauvegardes & monitoring %3A script de backup Postgres + sauvegarde des fichiers .env/SECRETS, rotation/prune Docker, alertes simples.%0A%0A1C %E2%80%94 VM LLM (GPU) %3A %C3%A0 cr%C3%A9er s%C3%A9par%C3%A9ment quand la GTX 1060 sera en passthrough.%0A%0A%0A(Ces notes d%C3%A9crivent l%E2%80%99%C3%A9tat apr%C3%A8s 1B %3A Supabase op%C3%A9rationnel, autostart, UFW, disques configur%C3%A9s, secrets centralis%C3%A9s.)
```

